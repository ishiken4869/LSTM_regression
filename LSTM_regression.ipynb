{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e8431b-5b14-4ce0-8d52-8eece073a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 300\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "SMILES_COL = 'Column3'\n",
    "REGRESSION_COL = 'Column8'\n",
    "URL = '/home/ishii/graduation_research/data/csvファイル/dft_B3LYP_6-31G*_zinc_for-sale_1000000_0to100000.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca771bf3-36b2-4fec-836d-266ac0d51e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#regression_col\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, url, smiles_col, regression_col):\n",
    "        self.max_length = 0\n",
    "        self.dummy_char = '_'\n",
    "        \n",
    "        self.url = url\n",
    "        self.smiles_col = smiles_col\n",
    "        self.smiles = []\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "        self.regression_col = regression_col\n",
    "        self.regressions = []\n",
    "        self.items = self.generate_items()\n",
    "        \n",
    "        self.dummmy_index = self.word_to_index[self.dummy_char]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv(self.url, usecols=[SMILES_COL])\n",
    "        self.smiles = list(train_df[self.smiles_col])\n",
    "        for i, smile in enumerate(self.smiles):\n",
    "            new_smile = smile[1:]\n",
    "            self.smiles[i] = new_smile\n",
    "        self.max_length = max(len(smile) for smile in self.smiles)\n",
    "        self.smiles = list(smile.ljust(self.max_length, self.dummy_char) for smile in self.smiles)\n",
    "        train_df = pd.Series(self.smiles)\n",
    "        text = train_df.str.cat(sep=' ')\n",
    "        text = \"\".join(text.split(' '))\n",
    "        return [text[i] for i in range(len(text))]\n",
    "    \n",
    "    def generate_items(self):\n",
    "        train_df = pd.read_csv(self.url, usecols=[REGRESSION_COL])\n",
    "        self.regressions = list(train_df[self.regression_col])\n",
    "        items = []\n",
    "        for i, smile in enumerate(self.smiles):\n",
    "            smile = list(smile)\n",
    "            items.append([self.word_to_index[w] for w in smile])\n",
    "        return items\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.regressions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.items[index]),\n",
    "            torch.tensor(self.regressions[index])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281d2fdc-f4d5-4996-a3c7-0a2a265c21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(url=URL, smiles_col=SMILES_COL, regression_col=REGRESSION_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0267ec8-658a-4e5c-8b58-ba5a20136c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 6,  1,  5,  1,  1,  1,  3,  2, 20,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0]), tensor(5.6882))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd788f74-7bb4-4c23-ab60-18fb3f15af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87628\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c80b1a8d-0167-41db-b0d3-c46072e6e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff953cc2-a21b-4620-b448-7d5395224691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  1,  5,  1,  1,  1,  1,  3,  6,  4,  1,  5,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  1,  5,  1,  1,  1,  3,  2, 20,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([6.0161, 5.6882])\n",
      "tensor([[ 2,  8,  2,  3,  2, 23,  9,  4,  2,  3,  8,  6,  4,  6,  2,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  1,  5,  1, 10,  1,  3,  2,  4,  1, 10,  5,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([5.7693, 5.4207])\n",
      "tensor([[ 2,  1,  5, 10,  1,  1, 10,  1,  5,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  2,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([5.4346, 5.8732])\n",
      "tensor([[ 2,  1,  5,  1,  1,  3,  6,  4,  1,  1,  1,  5,  2, 20,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  6,  1,  5,  1,  1,  1,  3,  6,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([5.6504, 5.3704])\n",
      "tensor([[ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1,  1,  1,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([5.5404, 5.8248])\n",
      "tensor([[ 9,  2,  2,  1,  5,  1,  1, 11, 10, 15, 12, 10,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  8,  2,  3,  6,  4,  1,  5,  1, 10,  1,  1, 10,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([7.0071, 4.9437])\n",
      "tensor([[ 2,  2,  5,  3,  2,  4,  2,  6,  2,  3,  9,  4,  8,  9,  5,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  1,  5, 10,  1, 10,  1,  7, 11, 10, 15, 12,  1, 10,  1,  5,  7,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([7.8340, 5.4672])\n",
      "tensor([[ 2,  6,  2,  3,  8,  6,  4,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1, 11, 10, 24, 12,  3, 11,  6,\n",
      "         17, 12,  4,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([5.5421, 4.2904])\n",
      "tensor([[ 2,  1,  5,  1,  1,  3,  6,  4,  1,  1,  3,  2,  4,  1,  5,  2, 20,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  1,  5, 22,  1,  7,  1,  1,  3,  6,  4,  1,  1,  1,  7, 21,  5,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([5.7927, 5.4066])\n",
      "tensor([[ 6,  2,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  1,  5,  1,  1,  3,  2,  4,  1,  3,  8,  6,  4, 11, 10, 15, 12, 10,\n",
      "          5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([6.1657, 4.7086])\n",
      "tensor([[ 6,  1,  5, 10, 21,  1,  7,  1,  1,  3,  2, 20,  4,  1,  1,  1,  5,  7,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  1,  5,  1,  1,  1,  1,  1,  5,  9,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([4.7690, 5.5853])\n"
     ]
    }
   ],
   "source": [
    "for batch, (x, y) in enumerate(dataloader):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    if batch == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963eec5a-0677-478b-8f00-91974d4e7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更後のモデル\n",
    "import torch\n",
    "\n",
    "class LSTM_Predictor(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(LSTM_Predictor, self).__init__()\n",
    "        self.lstm_size = 256\n",
    "        self.embedding_dim = 256\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            #padding_idxの処理が不明確\n",
    "            #padding_idx=dataset.dummmy_index\n",
    "        )\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(self.lstm_size, 1)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfd0211-c662-47bc-a69c-f76ddb5031c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更後の訓練プロセス\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train(dataset, train_dataset, model):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        state_h, state_c = model.init_state(BATCH_SIZE)\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        total_loss = 0\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for batch, (x, y) in enumerate(train_dataloader):\n",
    "            if batch < int(len(train_dataloader) * 0.75):\n",
    "                model.train()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "                y_pred_permute = torch.permute(y_pred, (2, 1, 0))\n",
    "                loss = criterion(y_pred_permute[0][dataset.max_length-1], y.to(device))\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "                y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "                y_pred_permute = torch.permute(y_pred, (2, 1, 0))\n",
    "                val_loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "                total_val_loss += val_loss.item()    \n",
    "                \n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "        \n",
    "        #scheduler.step()\n",
    "        \n",
    "        print(\"Epoch: {}, train_Loss: {:.3f}, val_Loss: {:.3f}\".format(\n",
    "            epoch+1, \n",
    "            total_loss / int(len(train_dataloader) * 0.75),\n",
    "            total_val_loss / (len(train_dataloader) - int(len(train_dataloader) * 0.75))\n",
    "        ))\n",
    "        losses.append(total_loss)\n",
    "        val_losses.append(total_val_loss)\n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67f788d-627e-42a1-89e3-38510896c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \" + str(device) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b912c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(url=URL, smiles_col=SMILES_COL, regression_col=REGRESSION_COL)\n",
    "n_samples = len(dataset)\n",
    "indices = list(range(n_samples))\n",
    "train_size = int(n_samples * 0.8)\n",
    "test_size = n_samples - train_size\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices[:train_size])\n",
    "test_dataset = torch.utils.data.Subset(dataset, indices[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7f1ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70102\n",
      "17526\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d15e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "print(int(len(train_dataloader) * 0.75))\n",
    "print(len(train_dataloader) - int(len(train_dataloader) * 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b9ca541-5e56-4e0f-a42b-5c1b0ec0c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_Loss: 0.629, val_Loss: 0.546\n",
      "Epoch: 2, train_Loss: 0.587, val_Loss: 0.547\n",
      "Epoch: 3, train_Loss: 0.587, val_Loss: 0.547\n",
      "Epoch: 4, train_Loss: 0.587, val_Loss: 0.547\n",
      "Epoch: 5, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 6, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 7, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 8, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 9, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 10, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 11, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 12, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 13, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 14, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 15, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 16, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 17, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 18, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 19, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 20, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 21, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 22, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 23, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 24, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 25, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 26, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 27, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 28, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 29, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 30, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 31, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 32, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 33, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 34, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 35, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 36, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 37, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 38, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 39, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 40, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 41, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 42, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 43, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 44, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 45, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 46, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 47, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 48, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 49, train_Loss: 0.587, val_Loss: 0.547\n",
      "Epoch: 50, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 51, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 52, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 53, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 54, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 55, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 56, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 57, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 58, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 59, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 60, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 61, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 62, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 63, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 64, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 65, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 66, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 67, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 68, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 69, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 70, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 71, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 72, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 73, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 74, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 75, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 76, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 77, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 78, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 79, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 80, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 81, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 82, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 83, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 84, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 85, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 86, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 87, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 88, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 89, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 90, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 91, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 92, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 93, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 94, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 95, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 96, train_Loss: 0.587, val_Loss: 0.547\n",
      "Epoch: 97, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 98, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 99, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 100, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 101, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 102, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 103, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 104, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 105, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 106, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 107, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 108, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 109, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 110, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 111, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 112, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 113, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 114, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 115, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 116, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 117, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 118, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 119, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 120, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 121, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 122, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 123, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 124, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 125, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 126, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 127, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 128, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 129, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 130, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 131, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 132, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 133, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 134, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 135, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 136, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 137, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 138, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 139, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 140, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 141, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 142, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 143, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 144, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 145, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 146, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 147, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 148, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 149, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 150, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 151, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 152, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 153, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 154, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 155, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 156, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 157, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 158, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 159, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 160, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 161, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 162, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 163, train_Loss: 0.588, val_Loss: 0.548\n",
      "Epoch: 164, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 165, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 166, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 167, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 168, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 169, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 170, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 171, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 172, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 173, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 174, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 175, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 176, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 177, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 178, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 179, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 180, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 181, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 182, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 183, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 184, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 185, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 186, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 187, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 188, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 189, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 190, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 191, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 192, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 193, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 194, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 195, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 196, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 197, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 198, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 199, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 200, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 201, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 202, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 203, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 204, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 205, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 206, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 207, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 208, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 209, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 210, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 211, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 212, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 213, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 214, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 215, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 216, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 217, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 218, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 219, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 220, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 221, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 222, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 223, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 224, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 225, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 226, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 227, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 228, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 229, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 230, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 231, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 232, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 233, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 234, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 235, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 236, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 237, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 238, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 239, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 240, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 241, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 242, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 243, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 244, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 245, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 246, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 247, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 248, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 249, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 250, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 251, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 252, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 253, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 254, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 255, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 256, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 257, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 258, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 259, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 260, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 261, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 262, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 263, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 264, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 265, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 266, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 267, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 268, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 269, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 270, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 271, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 272, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 273, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 274, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 275, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 276, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 277, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 278, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 279, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 280, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 281, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 282, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 283, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 284, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 285, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 286, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 287, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 288, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 289, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 290, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 291, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 292, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 293, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 294, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 295, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 296, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 297, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 298, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 299, train_Loss: 0.587, val_Loss: 0.548\n",
      "Epoch: 300, train_Loss: 0.587, val_Loss: 0.548\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Predictor(dataset)\n",
    "model = model.to(device)\n",
    "train_losses, val_losses = train(dataset, train_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a7152e-3438-43f2-9432-f1b189df9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predect(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=5, drop_last=True)\n",
    "\n",
    "    index = np.random.choice(len(test_dataloader))\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        smiles, wavelength = x, y\n",
    "        break\n",
    "    state_h, state_c = model.init_state(5)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    y_pred, (state_h, state_c) = model(smiles.to(device), (state_h, state_c))\n",
    "    y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "\n",
    "    print(y_pred_permute)\n",
    "    print(wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df41f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0825e-01,  8.0032e-02,  8.0032e-02,  8.0032e-02,  8.0032e-02],\n",
      "         [ 9.2042e-02,  4.0307e-01,  5.5638e-02,  4.0307e-01,  4.0307e-01],\n",
      "         [ 2.5028e-02,  1.6811e+00,  3.1727e-02,  1.6811e+00,  1.2192e+00],\n",
      "         [-2.9444e-02,  3.4267e+00, -5.7845e-03,  3.4267e+00,  2.7504e+00],\n",
      "         [-6.0883e-02,  4.3343e+00, -4.1425e-02,  4.3343e+00,  4.0142e+00],\n",
      "         [-7.7962e-02,  4.5958e+00, -6.9741e-02,  4.5958e+00,  4.5161e+00],\n",
      "         [-9.3846e-02,  4.6554e+00, -8.3664e-02,  4.6554e+00,  4.6383e+00],\n",
      "         [-1.1483e-01,  4.6686e+00, -9.9886e-02,  4.6686e+00,  4.6649e+00],\n",
      "         [-1.5285e-01,  4.6717e+00, -1.1760e-01,  4.6717e+00,  4.6709e+00],\n",
      "         [-1.8422e-01,  4.6725e+00, -1.2773e-01,  4.6725e+00,  4.6723e+00],\n",
      "         [-1.9220e-01,  4.6728e+00, -1.3581e-01,  4.6728e+00,  4.6727e+00],\n",
      "         [-1.4950e-01,  4.6728e+00, -1.0883e-01,  4.6728e+00,  4.6728e+00],\n",
      "         [-6.2690e-02,  4.6728e+00,  8.1338e-02,  4.6728e+00,  4.6728e+00],\n",
      "         [ 2.2640e-02,  4.6729e+00,  9.7686e-01,  4.6729e+00,  4.6729e+00],\n",
      "         [ 3.5528e-02,  4.6729e+00,  2.5844e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 2.4231e-03,  4.6729e+00,  3.8724e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [-3.1411e-02,  4.6729e+00,  4.4471e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [-5.9998e-02,  4.6729e+00,  4.6163e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [-8.5026e-02,  4.6729e+00,  4.6587e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [-1.1543e-01,  4.6729e+00,  4.6692e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 1.9947e-02,  4.6729e+00,  4.6718e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 1.5616e+00,  4.6729e+00,  4.6726e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 3.5206e+00,  4.6729e+00,  4.6728e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.3981e+00,  4.6729e+00,  4.6728e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6138e+00,  4.6729e+00,  4.6728e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6596e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6696e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6720e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6726e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6728e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6728e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00],\n",
      "         [ 4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00,  4.6729e+00]]],\n",
      "       device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "tensor([4.4789, 5.0128, 4.6577, 5.1543, 3.6800])\n"
     ]
    }
   ],
   "source": [
    "predect(dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc12867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "axes[0].plot(train_losses, label=\"train_Loss\")\n",
    "axes[0].plot(val_losses, label=\"val_Loss\")\n",
    "axes[0].grid()\n",
    "axes[0].set_xlabel(\"epoch\")\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "axes[1].plot(train_losses, label=\"train_Loss\")\n",
    "axes[1].plot(val_losses, label=\"val_Loss\")\n",
    "axes[1].grid()\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel(\"epoch\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91fdc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "    \n",
    "    criterion = torch.nn.L1Loss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    state_h, state_c = model.init_state(len(test_dataset))\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "        y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "        loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "    \n",
    "    return total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce14c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Loss: 0.644\n"
     ]
    }
   ],
   "source": [
    "print(\"test_Loss: {:.3f}\".format(test(dataset, test_dataset, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64cfc140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "\n",
    "state_h, state_c = model.init_state(len(test_dataset))\n",
    "state_h = state_h.to(device)\n",
    "state_c = state_c.to(device)\n",
    "\n",
    "for batch, (x, y) in enumerate(test_dataloader):\n",
    "\n",
    "    y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "    y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "    state_h = state_h.detach()\n",
    "    state_c = state_c.detach()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y.cpu().detach().numpy(), y_pred_permute[0, dataset.max_length-1].cpu().detach().numpy())\n",
    "plt.title(REGRESSION_COL)\n",
    "plt.xlabel(\"labels\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f18a3795fe5cb6a973482da1273789e92c21cec72867792a35f0dcfcd5bea518"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
